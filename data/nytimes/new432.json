{"url": "https://www.nytimes.com/2017/08/23/technology/a-hunt-for-ways-to-disrupt-the-work-of-online-radicalization.html?mcubz=0", "id": "432", "title": "A Hunt for Ways to Combat Online Radicalization", "text": "In fact, that\u2019s the battle plan. Several research groups in the United States and Europe now see the white supremacist and jihadi threats as two faces of the same coin. They\u2019re working on methods to fight both, together \u2014 and slowly, they have come up with ideas for limiting how these groups recruit new members to their cause.\n\nTheir ideas are grounded in a few truths about how extremist groups operate online, and how potential recruits respond. After speaking to many researchers, I compiled this rough guide for combating online radicalization.\n\nRecognize the internet as an extremist breeding ground.\n\nThe first step in combating online extremism is kind of obvious: It is to recognize the extremists as a threat.\n\nFor the Islamic State, that began to happen in the last few years. After a string of attacks in Europe and the United States by people who had been indoctrinated in the swamp of online extremism, politicians demanded action. In response, Google, Facebook, Microsoft and other online giants began identifying extremist content and systematically removing it from their services, and have since escalated their efforts.\n\nWhen it comes to fighting white supremacists, though, much of the tech industry has long been on the sidelines. This laxity has helped create a monster. In many ways, researchers said, white supremacists are even more sophisticated than jihadists in their use of the internet.\n\nThe earliest white nationalist sites date back to the founding era of the web. For instance, Stormfront.org, a pioneering hate site, was started as a bulletin board in 1990. White supremacist groups have also been proficient at spreading their messages using the memes, language and style that pervade internet subcultures. Beyond setting up sites of their own, they have more recently managed to spread their ideology to online groups that were once largely apolitical, like gaming and sci-fi groups.\n\nAnd they\u2019ve grown huge. \u201cThe white nationalist scene online in America is phenomenally larger than the jihadists\u2019 audience, which tends to operate under the radar,\u201d said Vidhya Ramalingam, the co-founder of Moonshot CVE, a London-based start-up that works with internet companies to combat violent extremism. \u201cIt\u2019s just a stunning difference between the audience size.\u201d\n\nNewsletter Sign Up Continue reading the main story Interested in All Things Tech? The Bits newsletter will keep you updated on the latest from Silicon Valley and the technology industry. Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services. Thank you for subscribing. An error has occurred. Please try again later. View all New York Times newsletters.\n\nAfter the horror of Charlottesville, internet companies began banning and blocking content posted by right-wing extremist groups. So far their efforts have been hasty and reactive, but Ms. Ramalingam sees it as at the start of a wider effort.\n\nAdvertisement Continue reading the main story\n\n\u201cIt\u2019s really an unprecedented moment where social media and tech companies are recognizing that their platforms have become spaces where these groups can grow, and have been often unpoliced,\u201d she said. \u201cThey\u2019re really kind of waking up to this and taking some action.\u201d\n\nEngage directly with potential recruits.\n\nIf tech companies are finally taking action to prevent radicalization, is it the right kind of action? Extremism researchers said that blocking certain content may work to temporarily disrupt groups, but may eventually drive them further underground, far from the reach of potential saviors.\n\nA more lasting plan involves directly intervening in the process of radicalization. Consider The Redirect Method, an anti-extremism project created by Jigsaw, a think tank founded by Google. The plan began with intensive field research. After interviews with many former jihadists, white supremacists and other violent extremists, Jigsaw discovered several important personality traits that may abet radicalization.\n\nOne factor is a skepticism of mainstream media. Whether on the far right or ISIS, people who are susceptible to extremist ideologies tend to dismiss outlets like The New York Times or the BBC, and they often go in search of alternative theories online.\n\nAnother key issue is timing. There\u2019s a brief window between initial interest in an extremist ideology and a decision to join the cause \u2014 and after recruits make that decision, they are often beyond the reach of outsiders. For instance, Jigsaw found that when jihadists began planning their trips to Syria to join ISIS, they had fallen too far down the rabbit hole and dismissed any new information presented to them.\n\nJigsaw put these findings to use in an innovative way. It curated a series of videos showing what life is truly like under the Islamic State in Syria and Iraq. The videos, which weren\u2019t filmed by news outlets, offered a credible counterpoint to the fantasies peddled by the group \u2014 they show people queuing up for bread, fighters brutally punishing civilians, and women and children being mistreated.\n\nThen, to make sure potential recruits saw the videos at the right time in their recruitment process, Jigsaw used one of Google\u2019s most effective technologies: ad targeting. In the same way that a pair of shoes you looked up last week follows you around the internet, Jigsaw\u2019s counterterrorism videos were pushed to likely recruits.\n\nAdvertisement Continue reading the main story\n\nJigsaw can\u2019t say for sure if the project worked, but it found that people spent lots of time watching the videos, which suggested they were of great interest, and perhaps dissuaded some from extremism.\n\n\n\nMoonshot CVE, which worked with Jigsaw on the Redirect project, put together several similar efforts to engage with both jihadists and white supremacist groups. It has embedded undercover social workers in extremist forums who discreetly message potential recruits to dissuade them. And lately it\u2019s been using targeted ads to offer mental health counseling to those who might be radicalized.\n\n\u201cWe\u2019ve seen that it\u2019s really effective to go beyond ideology,\u201d Ms. Ramalingam said. \u201cWhen you offer them some information about their lives, they\u2019re disproportionately likely to interact with it.\u201d\n\nWhat happens online isn\u2019t all that matters in the process of radicalization. The offline world obviously matters too. Dylann Roof \u2014 the white supremacist who murdered nine people at a historically African-American church in Charleston, S.C., in 2015 \u2014 was radicalized online. But as a new profile in GQ Magazine makes clear, there was much more to his crime than the internet, including his mental state and a racist upbringing.\n\nStill, just about every hate crime and terrorist attack, these days, was planned or in some way coordinated online. Ridding the world of all of the factors that drive young men to commit heinous acts isn\u2019t possible. But disrupting the online radicalization machine? With enough work, that may just be possible.", "authors": ["Farhad Manjoo", "State Of The Art"], "publish_date": "2017-08-23", "source": "nytimes", "top_words": ["internet", "radicalization", "began", "videos", "ways", "combat", "jihadists", "hunt", "online", "extremist", "groups", "white", "potential", "jigsaw"], "summary": "Their ideas are grounded in a few truths about how extremist groups operate online, and how potential recruits respond.\nThe first step in combating online extremism is kind of obvious: It is to recognize the extremists as a threat.\nIn response, Google, Facebook, Microsoft and other online giants began identifying extremist content and systematically removing it from their services, and have since escalated their efforts.\nBeyond setting up sites of their own, they have more recently managed to spread their ideology to online groups that were once largely apolitical, like gaming and sci-fi groups.\nAfter interviews with many former jihadists, white supremacists and other violent extremists, Jigsaw discovered several important personality traits that may abet radicalization."}